הנה מפרט מלא ומקיף של האפליקציה מההתחלה ועד הסוף - ברור, מובנה ומוכן להעתקה לצורך יצירת קוד:

---

# 📘 מפרט פרויקט: כלי לחלוקת וקידוד ספרים גדולים

## 🎯 סקירה כללית

כלי זה מיועד לעיבוד קבצי טקסט גדולים (ספרים) על ידי:
1. חלוקת הטקסט הגולמי לחתיכות ניתנות לניהול.
2. עיבוד כל חתיכה (למשל, תרגום, סיכום) באמצעות LLM.
3. חזרה על חתיכות שנכשלו או לא הושלמו לפי הצורך.
4. בנייה מחדש של החתיכות המעובדות לקובץ פלט סופי ושלם (למשל, ספר מתורגם).

המערכת תשתמש ב**קבצי JSON פשוטים** לכל האחסון. ללא מסד נתונים. ללא ממשק אינטרנט. שימוש פשוט מבוסס טרמינל עם שלושה סקריפטים:
- `chunk.py`
- `process.py`
- `rebuild.py`

---

## 🧩 שלב 1: סקריפט חלוקה (`chunk.py`)

### 📥 קלט:
- קובץ `.txt` גולמי (למשל `mybook.txt`)
- גודל חתיכה רצוי (למשל 1000 או 2000 תווים)

### 📤 פלט:
- קובץ JSON `מחולק` (למשל `mybook_chunked.json`) עם המבנה:

```json
{
  "meta": {
    "book_id": "mybook",
    "chunk_size": 1000,
    "total_chunks": 42
  },
  "chunks": [
    {
      "index": 0,
      "text": "1000 התווים הראשונים של הספר...",
      "status": "pending",
      "result": null
    },
    {
      "index": 1,
      "text": "1000 התווים הבאים של הספר...",
      "status": "pending",
      "result": null
    },
    ...
  ]
}
````

---

## ⚙️ שלב 2: סקריפט עיבוד (`process.py`)

### 📥 קלט:

* קובץ JSON `מחולק` (מ-`chunk.py`)
* תבנית הנחיה (למשל, "תרגם לספרדית: {text}")
* שם מודל (למשל, "gpt-4", "claude-3")
* מפתח API (דרך משתנה סביבה)

### 📤 פלט:

* מעדכן את אותו קובץ JSON עם התוצאות
* כל חתיכה כעת כוללת:

  * `status`: `"done"` או `"error"`
  * `result`: הטקסט המעובד (אם הצליח)
  * `error`: הודעת שגיאה (אם נכשל)

### 🔁 התנהגות העיבוד:

* הסקריפט מעבד רק חתיכות שבהן `status != "done"`
* כל חתיכה מנוסה רק פעם אחת בכל הרצה (ללא ניסיונות חוזרים)
* **שומר את קובץ ה-JSON אחרי כל חתיכה שמעובדת** (מיד אחרי כל קריאת LLM)
  - זה מבטיח שאף התקדמות לא תאבד אם הסקריפט קורס
  - ניתן לעצור בבטחה עם Ctrl+C ולהמשיך מאוחר יותר
  - כל שמירה כוללת את התוצאה/שגיאה העדכנית של אותה חתיכה
* מציג סרגל התקדמות מפורט עם:
  - מספר חתיכה נוכחית / סך החתיכות
  - ספירת הצלחות
  - ספירת כשלונות
  - מהירות עיבוד (חתיכות/דקה)
  - זמן משוער לסיום מבוסס על המהירות הנוכחית
  - עדכוני סטטוס חיים

דוגמה לתצוגת התקדמות:
```
מעבד: [████████░░░░░░░░░░░░] 42/100 חתיכות | ✓ 40 | ✗ 2 | מהירות: 3.2/דקה | זמן משוער: 18ד 45ש
```

---

## 🏗️ שלב 3: סקריפט בנייה מחדש (`rebuild.py`)

### 📥 קלט:

* קובץ JSON `מעובד` (מ-`process.py`)

### 📤 פלט:

* קובץ `.txt` סופי (למשל `mybook_translated_final.txt`)
* משרשר את כל ערכי ה-`result` לפי סדר החתיכות
* מציג סיכום של הבנייה:
  - סך החתיכות שנבנו מחדש
  - חתיכות חסרות כלשהן (שגיאות/ממתינות)
  - גודל קובץ הפלט

---

## ✅ סיכום הסקריפטים

### `chunk.py`

* קלט: `raw_book.txt`
* פלט: `chunked.json`
* תפקיד: חלוקה לחתיכות בגודל קבוע

### `process.py`

* קלט: `chunked.json`
* פלט: `processed.json`
* תפקיד: עיבוד (תרגום/סיכום/וכו') של כל חתיכה באמצעות LLM

### `rebuild.py`

* קלט: `processed.json`
* פלט: `final_output.txt`
* תפקיד: שילוב כל התוצאות לקובץ קריא סופי

---

## 📋 דוגמאות שימוש

```bash
# שלב 1: חלוקת ספר לחתיכות של 2000 תווים
python chunk.py mybook.txt --chunk-size 2000

# שלב 2: עיבוד חתיכות עם תרגום (ניתן להריץ מספר פעמים)
python process.py mybook_chunked.json --prompt "תרגם לספרדית: {text}" --model gpt-4

# אם חתיכות מסוימות נכשלו, פשוט הרץ שוב - זה יעבד רק חתיכות שנכשלו/ממתינות:
python process.py mybook_chunked.json --prompt "תרגם לספרדית: {text}" --model gpt-4

# שלב 3: בנייה מחדש לקובץ סופי
python rebuild.py mybook_chunked.json -o mybook_spanish.txt
```

## 📊 מעקב התקדמות

סקריפט process.py מספק מידע התקדמות בזמן אמת:

```
מתחיל עיבוד של mybook_chunked.json
נמצאו 100 חתיכות: 95 ממתינות, 5 כבר הושלמו

מעבד: [████████░░░░░░░░░░░░] 42/95 חתיכות | ✓ 40 | ✗ 2 | מהירות: 3.2/דקה | זמן משוער: 16ד 33ש
נוכחי: מעבד חתיכה 42 - "זו הייתה התקופה הטובה ביותר, זו הייתה..."

סיכום:
- סך החתיכות: 100
- עובדו בהצלחה: 45
- נכשלו: 2 (חתיכות: 23, 67)
- כבר הושלמו: 5
- זמן עיבוד: 14ד 3ש
```

## 🔧 הערות

* כל הנתונים נשמרים בקבצי JSON פשוטים
* **ההתקדמות נשמרת אחרי כל קריאת LLM** (בטוח לחלוטין מקריסות)
* ניתן להפסיק את העיבוד בכל עת מבלי לאבד עבודה
* קל לבדוק ולערוך חתיכות באופן ידני
* עיצוב פשוט המאפשר שיפורים עתידיים

---

**מערכת זו מתוכננת לפשטות ואיטרציה. בנה מהר, שפר מאוחר יותר.**